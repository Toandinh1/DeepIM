{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMeaZ02UdC6PQM5c7yXoVIa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Toandinh1/DeepIM/blob/master/10_1_2022.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRe_STj1eMMc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from scipy.special import binom\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers import Lambda, Reshape, Dense, Input, Activation\n",
        "\n",
        "#from keras import backend as K\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "N = 4 # number of sub-carriers\n",
        "K = 1 # number of active sub-carriers\n",
        "M = 4 # M-ary modulation order\n",
        "\n",
        "SNRdb = 7 # Training SNR\n",
        "\n",
        "traing_epochs = 200\n",
        "l_rate = 0.001\n",
        "total_batch = 20 # number of batches per epoch\n",
        "batch_size = 200\n",
        "\n",
        "\n",
        "n_output_1 = 16\n",
        "n_output_2 = 32\n",
        "n_input_1 = N\n",
        "n_input_2 = 2*N\n",
        "\n",
        "\n",
        "m = int(np.log2(M))\n",
        "c = int(np.log2(binom(N,K)))\n",
        "q = K*m + c # number of bits per OFDM-IM symbol\n",
        "Q= 2**q\n",
        "n_output = c\n",
        "\n",
        "c1 = 4\n",
        "c2 = 1\n",
        "\n",
        "SNR = 10**(SNRdb/10)\n",
        "sigma = np.sqrt(1/SNR)\n",
        "\n",
        "display_step = 5\n",
        "qam_factor = (2/3)*(M-1)\n",
        "\n",
        "\n",
        "a = 1/np.sqrt(2)\n",
        "\n",
        "# M-ary modulations\n",
        "if M==4:\n",
        "    QAM = np.array([1+0j, 0+1j, -0-1j, -1+0j], dtype=complex) # gray mapping\n",
        "elif M==8:\n",
        "    QAM = np.array([1, a+a*1j, -a+a*1j, 1j, a-a*1j, -1j, -1, -a-a*1j], dtype=complex) # 8PSK, not 8QAM indeed\n",
        "    qam_factor = 1\n",
        "elif M==16:\n",
        "    QAM = np.array([-3+3j, -3+1j, -3-3j, -3-1j, \n",
        "                    -1+3j, -1+1j, -1-3j, -1-1j, \n",
        "                    3+3j, 3+1j, 3-3j, 3-1j, \n",
        "                    1+3j, 1+1j, 1-3j, 1-1j], dtype=complex)\n",
        "else:\n",
        "    QAM = np.array([1,-1], dtype=complex) #BPSK\n",
        "    qam_factor = 1\n",
        "\n",
        "\n",
        "# index patterns for N=4 and K=1,2,3 only\n",
        "if K==1:\n",
        "    idx = np.array([[0],[1],[2],[3]])\n",
        "elif K==2:\n",
        "    idx = np.array([[0,1],[2,3],[0,2],[1,3]]) \n",
        "else:\n",
        "    idx = np.array([[0,1,2],[1,2,3],[0,2,3],[0,1,3]]) \n",
        "def SC_IM_NO_train(bit1,bit2, SNRdb):\n",
        "        #user1\n",
        "    bit_id1 = bit1[0:c:1]\n",
        "    id_de1 = bit_id1.dot(2**np.arange(bit_id1.size)[::-1])\n",
        "    bit_sy1 = bit1[c:q:1]   \n",
        "    bit_K1 = bit_sy1.reshape(-1,m)\n",
        "    sy_de1 = np.zeros((K,), dtype=int)\n",
        "    sym1 = np.zeros((K,), dtype=complex)\n",
        "    one_hot_bit1 = np.zeros((16,),dtype=int)\n",
        "    for i in range(K):\n",
        "        bit_sy_i1 = bit_K1[i,:]\n",
        "        sy_de1[i] = bit_sy_i1.dot(2**np.arange(bit_sy_i1.size)[::-1])\n",
        "        sym1[i] = QAM[sy_de1[i]]\n",
        "\n",
        "    tx_sym1 = np.zeros((N,), dtype=complex)\n",
        "    tx_sym1[idx[id_de1,:]] = sym1\n",
        "    tx_sym1 = tx_sym1*np.sqrt(c1)\n",
        "    one_hot1 = 0\n",
        "    for i in range(M):\n",
        "      if bit1[i] == 1:\n",
        "        one_hot1 = one_hot1 + 2**i\n",
        "      else:\n",
        "        one_hot1 = one_hot1 + 0\n",
        "    one_hot_bit1[one_hot1] = 1\n",
        "  #user2\n",
        "    bit_id2 = bit2[0:c:1]\n",
        "    id_de2 = bit_id2.dot(2**np.arange(bit_id2.size)[::-1])\n",
        "    bit_sy2 = bit2[c:q:1]   \n",
        "    bit_K2 = bit_sy2.reshape(-1,m)\n",
        "    sy_de2 = np.zeros((K,), dtype=int)\n",
        "    sym2 = np.zeros((K,), dtype=complex)\n",
        "    one_hot_bit2  = np.zeros((16,),dtype=int)\n",
        "    for i in range(K):\n",
        "        bit_sy_i2 = bit_K2[i,:]\n",
        "        sy_de2[i] = bit_sy_i2.dot(2**np.arange(bit_sy_i2.size)[::-1])\n",
        "        sym2[i] = QAM[sy_de2[i]]\n",
        "\n",
        "    tx_sym2 = np.zeros((N,), dtype=complex)\n",
        "    tx_sym2[idx[id_de2,:]] = sym2\n",
        "    tx_sym2 = tx_sym2*np.sqrt(c2)\n",
        "    one_hot2 = 0\n",
        "    for i in range(M):\n",
        "      if bit2[i] == 1:\n",
        "        one_hot2 = one_hot2 + 2**i\n",
        "      else:\n",
        "        one_hot2 = one_hot2 + 0\n",
        "    one_hot_bit2[one_hot2] = 1\n",
        "\n",
        "    #transmision\n",
        "    SNR = 10**(SNRdb/10)\n",
        "    sigma = np.sqrt(1/SNR)\n",
        "    noise = sigma*np.sqrt(1/2)*(np.random.randn(*tx_sym1.shape)+1j*np.random.randn(*tx_sym1.shape))\n",
        "    #noise = np.random.normal(0, 1, tx_sym1.shape)\n",
        "    #H1 = 1\n",
        "    #H2 = 1\n",
        "    H1 = 4*np.sqrt(1/2)*(np.random.randn(*tx_sym1.shape)+1j*np.random.randn(*tx_sym1.shape))\n",
        "    H2 = np.sqrt(1/2)*(np.random.randn(*tx_sym2.shape)+1j*np.random.randn(*tx_sym2.shape))\n",
        "    y = H1*tx_sym1 + H2*tx_sym2 + noise\n",
        "     \n",
        "    y_bar = y/ H1\n",
        "    y_con = np.concatenate((np.real(y_bar),np.imag(y_bar)))\n",
        "    y_m = np.absolute(y_bar)\n",
        "    Y =np.concatenate((y_con,y_m))\n",
        "    \n",
        "    return Y,y_con\n",
        "    \n",
        "  \n",
        "    \n",
        "\n",
        "def SC_IM_NO_test(bit1, bit2, SNRdb):\n",
        "        #user1\n",
        "    bit_id1 = bit1[0:c:1]\n",
        "    id_de1 = bit_id1.dot(2**np.arange(bit_id1.size)[::-1])\n",
        "    bit_sy1 = bit1[c:q:1]   \n",
        "    bit_K1 = bit_sy1.reshape(-1,m)\n",
        "    sy_de1 = np.zeros((K,), dtype=int)\n",
        "    sym1 = np.zeros((K,), dtype=complex)\n",
        "    one_hot_bit1 = np.zeros((16,),dtype=int)\n",
        "    for i in range(K):\n",
        "        bit_sy_i1 = bit_K1[i,:]\n",
        "        sy_de1[i] = bit_sy_i1.dot(2**np.arange(bit_sy_i1.size)[::-1])\n",
        "        sym1[i] = QAM[sy_de1[i]]\n",
        "\n",
        "    tx_sym1 = np.zeros((N,), dtype=complex)\n",
        "    tx_sym1[idx[id_de1,:]] = sym1\n",
        "    tx_sym1 = tx_sym1*np.sqrt(c1)\n",
        "    one_hot1 = 0\n",
        "    for i in range(M):\n",
        "      if bit1[i] == 1:\n",
        "        one_hot1 = one_hot1 + 2**i\n",
        "      else:\n",
        "        one_hot1 = one_hot1 + 0\n",
        "    one_hot_bit1[one_hot1] = 1\n",
        "  #user2\n",
        "    bit_id2 = bit2[0:c:1]\n",
        "    id_de2 = bit_id2.dot(2**np.arange(bit_id2.size)[::-1])\n",
        "    bit_sy2 = bit2[c:q:1]   \n",
        "    bit_K2 = bit_sy2.reshape(-1,m)\n",
        "    sy_de2 = np.zeros((K,), dtype=int)\n",
        "    sym2 = np.zeros((K,), dtype=complex)\n",
        "    one_hot_bit2 = np.zeros((16,),dtype=int)\n",
        "    for i in range(K):\n",
        "        bit_sy_i2 = bit_K2[i,:]\n",
        "        sy_de2[i] = bit_sy_i2.dot(2**np.arange(bit_sy_i2.size)[::-1])\n",
        "        sym2[i] = QAM[sy_de2[i]]\n",
        "\n",
        "    tx_sym2 = np.zeros((N,), dtype=complex)\n",
        "    tx_sym2[idx[id_de2,:]] = sym2\n",
        "    tx_sym2 = tx_sym2*np.sqrt(c2)\n",
        "    one_hot2 = 0\n",
        "    for i in range(M):\n",
        "      if bit2[i] == 1:\n",
        "        one_hot2 = one_hot2 + 2**i\n",
        "      else:\n",
        "        one_hot2 = one_hot2 + 0\n",
        "    one_hot_bit2[one_hot2] = 1\n",
        "\n",
        "    #transmision\n",
        "    SNR = 10**(SNRdb/10)\n",
        "    sigma = np.sqrt(1/SNR)\n",
        "    noise = sigma*np.sqrt(1/2)*(np.random.randn(*tx_sym1.shape)+1j*np.random.randn(*tx_sym1.shape))\n",
        "    #noise = np.random.normal(0, 1, tx_sym1.shape)\n",
        "    #H1 = 1\n",
        "    #H2 = 1\n",
        "    H1 = 4*np.sqrt(1/2)*(np.random.randn(*tx_sym1.shape)+1j*np.random.randn(*tx_sym1.shape))\n",
        "    H2 = np.sqrt(1/2)*(np.random.randn(*tx_sym2.shape)+1j*np.random.randn(*tx_sym2.shape))\n",
        "    y = H1*tx_sym1 + H2*tx_sym2 + noise\n",
        "     \n",
        "    y_bar = y/ H1\n",
        "    y_con = np.concatenate((np.real(y_bar),np.imag(y_bar)))\n",
        "    y_m = np.absolute(y_bar)\n",
        "    Y =np.concatenate((y_con,y_m))\n",
        "    \n",
        "    return Y,y_con\n",
        "#model     \n",
        "ini = 'glorot_uniform'\n",
        "init=tf.global_variables_initializer()\n",
        "X = tf.placeholder(\"float\", [None, 12])\n",
        "Y = tf.placeholder(\"float\", [None, 16])\n",
        "initializer = tf.contrib.layers.xavier_initializer()\n",
        "\n",
        "def encoderA1(x1):\n",
        "     weights = {                    \n",
        "        'encoder_h1': tf.Variable(initializer([12, 16])),\n",
        "        'encoder_h2': tf.Variable(initializer([12, 16])), \n",
        "        'encoder_h3': tf.Variable(initializer([12, 16])),\n",
        "          \n",
        "     }\n",
        "     biases = {            \n",
        "        'encoder_b1': tf.Variable(initializer([16])),\n",
        "        'encoder_b2': tf.Variable(initializer([16])),\n",
        "        'encoder_b3': tf.Variable(initializer([16])),          \n",
        "     }\n",
        "    #layer_1 = tf.nn.tanh(tf.add(tf.matmul(x, weights['encoder_h1']), biases['encoder_b1']))\n",
        "    #layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['encoder_h2']), biases['encoder_b2']))\n",
        "    #layer_fisrt = Dense(12, activation='linear', init=ini)(x)\n",
        "    #layer_batch = BatchNormalization(momentum=0.99, epsilon=0.00001, center=True,scale=True)(layer_fisrt)\n",
        "     layer_1 = Dense(12, activation=tf.nn.relu, init=ini)(x)\n",
        "     layer_batch = BatchNormalization(momentum=0.99, epsilon=0.00001, center=True,scale=True)(layer_1)\n",
        "     Q= tf.add(tf.matmul(layer_batch, weights['encoder_h1']), biases['encoder_b1'])\n",
        "     #K = Dense(16, activation='linear', init=ini)(layer_batch)\n",
        "     #V = Dense(16, activation='linear', init=ini)(layer_batch)\\\n",
        "     #E = tf.matmul(Q,K)\n",
        "     K= tf.add(tf.matmul(layer_batch, weights['encoder_h2']), biases['encoder_b2'])\n",
        "     V= tf.add(tf.matmul(layer_batch, weights['encoder_h3']), biases['encoder_b3'])\n",
        "     E= tf.matmul(Q, K)\n",
        "     layer_3 = Dense(12, activation=tf.nn.sigmoid, init=ini)(E)\n",
        "     A1 = tf.matmul(layer_3,V)\n",
        "     return A1\n",
        "def encoderA2(x2):\n",
        "     weights = {                    \n",
        "        'encoder_h1': tf.Variable(initializer([12, 16])),\n",
        "        'encoder_h2': tf.Variable(initializer([12, 16])), \n",
        "        'encoder_h3': tf.Variable(initializer([12, 16])),\n",
        "          \n",
        "     }\n",
        "     biases = {            \n",
        "        'encoder_b1': tf.Variable(initializer([16])),\n",
        "        'encoder_b2': tf.Variable(initializer([16])),\n",
        "        'encoder_b3': tf.Variable(initializer([16])),          \n",
        "     }\n",
        "    #layer_1 = tf.nn.tanh(tf.add(tf.matmul(x, weights['encoder_h1']), biases['encoder_b1']))\n",
        "    #layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['encoder_h2']), biases['encoder_b2']))\n",
        "    #layer_fisrt = Dense(12, activation='linear', init=ini)(x)\n",
        "    #layer_batch = BatchNormalization(momentum=0.99, epsilon=0.00001, center=True,scale=True)(layer_fisrt)\n",
        "     layer_1 = Dense(12, activation=tf.nn.relu, init=ini)(x)\n",
        "     layer_batch = BatchNormalization(momentum=0.99, epsilon=0.00001, center=True,scale=True)(layer_1)\n",
        "     Q= tf.add(tf.matmul(layer_batch, weights['encoder_h1']), biases['encoder_b1'])\n",
        "     #K = Dense(16, activation='linear', init=ini)(layer_batch)\n",
        "     #V = Dense(16, activation='linear', init=ini)(layer_batch)\\\n",
        "     #E = tf.matmul(Q,K)\n",
        "     K= tf.add(tf.matmul(layer_batch, weights['encoder_h2']), biases['encoder_b2'])\n",
        "     V= tf.add(tf.matmul(layer_batch, weights['encoder_h3']), biases['encoder_b3'])\n",
        "     E= tf.matmul(Q, K)\n",
        "     layer_3 = Dense(12, activation=tf.nn.sigmoid, init=ini)(E)\n",
        "     A2 = tf.matmul(layer_3,V)\n",
        "     return A2\n",
        "def encoder(x3,x4):\n",
        "    layer_1= tf.concat(x3,x4,axis=-1)\n",
        "    A = Dense(12, activation='linear', init=ini)(layer_1)\n",
        "    normA= BatchNormalization(momentum=0.99, epsilon=0.00001, center=True,scale=True)(A)\n",
        "    P = Dense(12, activation=tf.nn.gelu, init=ini)(normA)\n",
        "    O = Dense(12, activation='linear', init=ini)(P)\n",
        "    return O\n",
        "#y_pred = encoder(X)\n",
        "#y_true = Y\n",
        "\n",
        "#cost = tf.reduce_mean(tf.pow(y_true - y_pred, 2))\n",
        "#learning_rate = tf.placeholder(tf.float32, shape=[])\n",
        "#optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "#init = tf.global_variables_initializer()\n",
        "#def detobit(A):\n",
        "  #x= np.zeros((4,))\n",
        "  #y= np.zeros((4,))\n",
        "  #x[0] = A//2\n",
        "  #y[0] = A%2\n",
        "  #x[1] = x[0]//2\n",
        "  #y[1] = x[0]%2\n",
        "  #x[2] = x[1]//2\n",
        "  #y[2] = x[1]%2\n",
        "  #x[3] = x[2]//2\n",
        "  #y[3] = x[2]%2\n",
        "  #bit_est =np.array([y[0],y[1],y[2],y[3]],dtype= int)\n",
        "  #return bit_est\n",
        "\n",
        "def frange(x,y,jump):\n",
        "    while x < y:\n",
        "        yield x\n",
        "        x +=jump\n",
        "\n",
        "EbNodB_range = list(frange(0,50,5))\n",
        "BER1 = [None]*len(EbNodB_range)\n",
        "\n",
        "\n",
        "with tf.Session() as sess:\n",
        "#Training\n",
        "    sess.run(init)\n",
        "    for epoch in range(traing_epochs):\n",
        "        avg_cost = 0\n",
        "        for index_m in range(total_batch):\n",
        "            input_samples = []\n",
        "            input_samples1 = []\n",
        "            input_labels = []\n",
        "            \n",
        "            for index_k in range(0, batch_size):\n",
        "                bits1 = np.random.binomial(n=1,p=0.5,size=(q,))\n",
        "                bits2 = np.random.binomial(n=1,p=0.5,size=(q,))\n",
        "                signaloutput,y_con,one_hot_bit1,one_hot_bit2 = SC_IM_NO_train(bits1,bits2,10)\n",
        "                input_labels.append(one_hot_bit1)\n",
        "                input_samples.append(signaloutput)\n",
        "                \n",
        "               \n",
        "\n",
        "            batch_x = np.asarray(input_samples)\n",
        "            batch_xx = np.asarray(input_samples1)\n",
        "            batch_y = np.asarray(input_labels)\n",
        "           \n",
        "            \n",
        "            \n",
        "\n",
        "            _,cs = sess.run([optimizer,cost], feed_dict={X:batch_x,\n",
        "                                                        Y:batch_y,\n",
        "                                                        learning_rate:l_rate})\n",
        "            avg_cost += cs / total_batch\n",
        "        if epoch % display_step == 0:\n",
        "            print(\"Epoch:\",'%04d' % (epoch+1), \"cost=\", \\\n",
        "               \"{:.9f}\".format(avg_cost))\n",
        "#==========Testing=============\n",
        "    for n in range(0,len(EbNodB_range)):\n",
        "      input_samples_test = []\n",
        "      input_samples1_test = []\n",
        "      input_labels_test = []\n",
        "      \n",
        "      test_number = 100000\n",
        "      if n>3:\n",
        "        test_number = 100000\n",
        "      for i in range(0, test_number):\n",
        "        bits1 = np.random.binomial(n=1, p=0.5, size=(q, )) \n",
        "        bits2 = np.random.binomial(n=1, p=0.5, size=(q, ))\n",
        "        signaloutput,y_con,one_hot_bit1,one_hot_bit2 = SC_IM_NO_train(bits1,bits2,EbNodB_range[n])\n",
        "        input_labels_test.append(bits1)\n",
        "        input_samples_test.append(signaloutput)\n",
        "        \n",
        "  \n",
        "  \n",
        "      batch_1 = np.asarray(input_samples_test)\n",
        "      batch_2 = np.asarray(input_labels_test)\n",
        "      one_hot_bit1_est= sess.run(y_pred,feed_dict={X:batch_1})\n",
        "      bit_error = 0\n",
        "      for i in range(0, test_number):\n",
        "        ind_est =np.argmax(one_hot_bit1_est[i,])\n",
        "        bit_est = detobit(ind_est)\n",
        "        bit_error =bit_error+sum(bit_est!=batch_2[i,])\n",
        "      BER1[n] = bit_error/(test_number*q)\n",
        "    print(\"SNR=\", EbNodB_range[n], \"BER:\", BER1[n])\n",
        "    #ML1=[0.133100000000000,\t0.0551562500000000,\t0.0170187500000000,\t0.00188125000000000,\t5.62500000000000e-05,\t0,\t0]\n",
        "    import matplotlib.pyplot as plt\n",
        "    plt.plot(EbNodB_range, BER1, 'bo-',label='DL')\n",
        "    #plt.plot(EbNodB_range, ML1, 'ro-',label='ML')\n",
        "    #plt.plot(list(EbNodB_range), ber_theory, 'ro-',label='BPSK BER')\n",
        "    plt.yscale('log')\n",
        "    plt.xlabel('SNR Range')\n",
        "    plt.ylabel('BER')\n",
        "    plt.grid()\n",
        "    plt.legend(loc='upper right',ncol = 1)\n",
        "    plt.savefig('DL_Detection_IM_BER_matplotlib')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Mon Oct  3 14:22:45 2022\n",
        "\n",
        "@author: GIT3HC\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from scipy.special import binom\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers import Lambda, Reshape, Dense, Input, Activation\n",
        "import torch\n",
        "import torchvision\n",
        "#from keras import backend as K\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "N = 4 # number of sub-carriers\n",
        "K = 1 # number of active sub-carriers\n",
        "M = 4 # M-ary modulation order\n",
        "\n",
        "SNRdb = 7 # Training SNR\n",
        "\n",
        "traing_epochs = 200\n",
        "l_rate = 0.001\n",
        "total_batch = 20 # number of batches per epoch\n",
        "batch_size = 200\n",
        "\n",
        "\n",
        "n_output_1 = 16\n",
        "n_output_2 = 32\n",
        "n_input_1 = N\n",
        "n_input_2 = 2*N\n",
        "\n",
        "\n",
        "m = int(np.log2(M))\n",
        "c = int(np.log2(binom(N,K)))\n",
        "q = K*m + c # number of bits per OFDM-IM symbol\n",
        "Q= 2**q\n",
        "n_output = c\n",
        "\n",
        "c1 = 4\n",
        "c2 = 1\n",
        "\n",
        "SNR = 10**(SNRdb/10)\n",
        "sigma = np.sqrt(1/SNR)\n",
        "\n",
        "display_step = 5\n",
        "qam_factor = (2/3)*(M-1)\n",
        "\n",
        "\n",
        "a = 1/np.sqrt(2)\n",
        "\n",
        "# M-ary modulations\n",
        "if M==4:\n",
        "    QAM = np.array([1+0j, 0+1j, -0-1j, -1+0j], dtype=complex) # gray mapping\n",
        "elif M==8:\n",
        "    QAM = np.array([1, a+a*1j, -a+a*1j, 1j, a-a*1j, -1j, -1, -a-a*1j], dtype=complex) # 8PSK, not 8QAM indeed\n",
        "    qam_factor = 1\n",
        "elif M==16:\n",
        "    QAM = np.array([-3+3j, -3+1j, -3-3j, -3-1j, \n",
        "                    -1+3j, -1+1j, -1-3j, -1-1j, \n",
        "                    3+3j, 3+1j, 3-3j, 3-1j, \n",
        "                    1+3j, 1+1j, 1-3j, 1-1j], dtype=complex)\n",
        "else:\n",
        "    QAM = np.array([1,-1], dtype=complex) #BPSK\n",
        "    qam_factor = 1\n",
        "\n",
        "\n",
        "# index patterns for N=4 and K=1,2,3 only\n",
        "if K==1:\n",
        "    idx = np.array([[0],[1],[2],[3]])\n",
        "elif K==2:\n",
        "    idx = np.array([[0,1],[2,3],[0,2],[1,3]]) \n",
        "else:\n",
        "    idx = np.array([[0,1,2],[1,2,3],[0,2,3],[0,1,3]]) \n",
        "def SC_IM_NO_train(bit1,bit2, SNRdb):\n",
        "        #user1\n",
        "    bit_id1 = bit1[0:c:1]\n",
        "    id_de1 = bit_id1.dot(2**np.arange(bit_id1.size)[::-1])\n",
        "    bit_sy1 = bit1[c:q:1]   \n",
        "    bit_K1 = bit_sy1.reshape(-1,m)\n",
        "    sy_de1 = np.zeros((K,), dtype=int)\n",
        "    sym1 = np.zeros((K,), dtype=complex)\n",
        "    for i in range(K):\n",
        "        bit_sy_i1 = bit_K1[i,:]\n",
        "        sy_de1[i] = bit_sy_i1.dot(2**np.arange(bit_sy_i1.size)[::-1])\n",
        "        sym1[i] = QAM[sy_de1[i]]\n",
        "\n",
        "    tx_sym1 = np.zeros((N,), dtype=complex)\n",
        "    tx_sym1[idx[id_de1,:]] = sym1\n",
        "    tx_sym1 = tx_sym1*np.sqrt(c1)\n",
        "    one_hot1 = np.zeros((N,M+1), dtype=int)\n",
        "    for i in range(M):\n",
        "       if tx_sym1[i] == 0+0j:\n",
        "        one_hot1[i,M] = 1\n",
        "       else:\n",
        "        one_hot1[i,M] = 0\n",
        "        one_hot1[i,id_de1] = 1\n",
        "  \n",
        "  #user2\n",
        "    bit_id2 = bit2[0:c:1]\n",
        "    id_de2 = bit_id2.dot(2**np.arange(bit_id2.size)[::-1])\n",
        "    bit_sy2 = bit2[c:q:1]   \n",
        "    bit_K2 = bit_sy2.reshape(-1,m)\n",
        "    sy_de2 = np.zeros((K,), dtype=int)\n",
        "    sym2 = np.zeros((K,), dtype=complex)\n",
        "    for i in range(K):\n",
        "        bit_sy_i2 = bit_K2[i,:]\n",
        "        sy_de2[i] = bit_sy_i2.dot(2**np.arange(bit_sy_i2.size)[::-1])\n",
        "        sym2[i] = QAM[sy_de2[i]]\n",
        "\n",
        "    tx_sym2 = np.zeros((N,), dtype=complex)\n",
        "    tx_sym2[idx[id_de2,:]] = sym2\n",
        "    tx_sym2 = tx_sym2*np.sqrt(c2)\n",
        "    one_hot2 = np.zeros((N,M+1), dtype=int)\n",
        "    for i in range(M):\n",
        "       if tx_sym2[i] == 0+0j:\n",
        "        one_hot2[i,M] = 1\n",
        "       else:\n",
        "        one_hot2[i,M] = 0\n",
        "        one_hot2[i,id_de2] = 1\n",
        "\n",
        "    #transmision\n",
        "    SNR = 10**(SNRdb/10)\n",
        "    sigma = np.sqrt(1/SNR)\n",
        "    noise = sigma*np.sqrt(1/2)*(np.random.randn(*tx_sym1.shape)+1j*np.random.randn(*tx_sym1.shape))\n",
        "    #noise = np.random.normal(0, 1, tx_sym1.shape)\n",
        "    #H1 = 1\n",
        "    #H2 = 1\n",
        "    H1 = 4*np.sqrt(1/2)*(np.random.randn(*tx_sym1.shape)+1j*np.random.randn(*tx_sym1.shape))\n",
        "    H2 = np.sqrt(1/2)*(np.random.randn(*tx_sym2.shape)+1j*np.random.randn(*tx_sym2.shape))\n",
        "    y = H1*tx_sym1 + H2*tx_sym2 + noise\n",
        "     \n",
        "    y_bar = y/ H1\n",
        "    #y_con = np.concatenate((np.real(y_bar),np.imag(y_bar)),axis=-1)\n",
        "    y_con = np.stack((np.real(y_bar),np.imag(y_)), axis=1)\n",
        "    y_m = np.absolute(y_bar)\n",
        "    Y =np.stack((y_con,y_m), axis=1)\n",
        "    \n",
        "    return Y,one_hot1,one_hot2\n",
        "    \n",
        "  \n",
        "    \n",
        "\n",
        "def SC_IM_NO_test(bit1, bit2, SNRdb):\n",
        "            #user1\n",
        "    bit_id1 = bit1[0:c:1]\n",
        "    id_de1 = bit_id1.dot(2**np.arange(bit_id1.size)[::-1])\n",
        "    bit_sy1 = bit1[c:q:1]   \n",
        "    bit_K1 = bit_sy1.reshape(-1,m)\n",
        "    sy_de1 = np.zeros((K,), dtype=int)\n",
        "    sym1 = np.zeros((K,), dtype=complex)\n",
        "    for i in range(K):\n",
        "        bit_sy_i1 = bit_K1[i,:]\n",
        "        sy_de1[i] = bit_sy_i1.dot(2**np.arange(bit_sy_i1.size)[::-1])\n",
        "        sym1[i] = QAM[sy_de1[i]]\n",
        "\n",
        "    tx_sym1 = np.zeros((N,), dtype=complex)\n",
        "    tx_sym1[idx[id_de1,:]] = sym1\n",
        "    tx_sym1 = tx_sym1*np.sqrt(c1)\n",
        "    one_hot1 = np.zeros((N,M+1), dtype=int)\n",
        "    for i in range(M):\n",
        "       if tx_sym1[i] == 0+0j:\n",
        "        one_hot1[i,M] = 1\n",
        "       else:\n",
        "        one_hot1[i,M] = 0\n",
        "        one_hot1[i,id_de1] = 1\n",
        "  \n",
        "  #user2\n",
        "    bit_id2 = bit2[0:c:1]\n",
        "    id_de2 = bit_id2.dot(2**np.arange(bit_id2.size)[::-1])\n",
        "    bit_sy2 = bit2[c:q:1]   \n",
        "    bit_K2 = bit_sy2.reshape(-1,m)\n",
        "    sy_de2 = np.zeros((K,), dtype=int)\n",
        "    sym2 = np.zeros((K,), dtype=complex)\n",
        "    for i in range(K):\n",
        "        bit_sy_i2 = bit_K2[i,:]\n",
        "        sy_de2[i] = bit_sy_i2.dot(2**np.arange(bit_sy_i2.size)[::-1])\n",
        "        sym2[i] = QAM[sy_de2[i]]\n",
        "\n",
        "    tx_sym2 = np.zeros((N,), dtype=complex)\n",
        "    tx_sym2[idx[id_de2,:]] = sym2\n",
        "    tx_sym2 = tx_sym2*np.sqrt(c2)\n",
        "    one_hot2 = np.zeros((N,M+1), dtype=int)\n",
        "    for i in range(M):\n",
        "       if tx_sym2[i] == 0+0j:\n",
        "        one_hot2[i,M] = 1\n",
        "       else:\n",
        "        one_hot2[i,M] = 0\n",
        "        one_hot2[i,id_de2] = 1\n",
        "\n",
        "    #transmision\n",
        "    SNR = 10**(SNRdb/10)\n",
        "    sigma = np.sqrt(1/SNR)\n",
        "    noise = sigma*np.sqrt(1/2)*(np.random.randn(*tx_sym1.shape)+1j*np.random.randn(*tx_sym1.shape))\n",
        "    #noise = np.random.normal(0, 1, tx_sym1.shape)\n",
        "    #H1 = 1\n",
        "    #H2 = 1\n",
        "    H1 = 4*np.sqrt(1/2)*(np.random.randn(*tx_sym1.shape)+1j*np.random.randn(*tx_sym1.shape))\n",
        "    H2 = np.sqrt(1/2)*(np.random.randn(*tx_sym2.shape)+1j*np.random.randn(*tx_sym2.shape))\n",
        "    y = H1*tx_sym1 + H2*tx_sym2 + noise\n",
        "     \n",
        "    y_bar = y/ H1\n",
        "    #y_con = np.concatenate((np.real(y_bar),np.imag(y_bar)),axis=-1)\n",
        "    y_con = np.stack((np.real(y_bar),np.imag(y_)), axis=1)\n",
        "    y_m = np.absolute(y_bar)\n",
        "    Y =np.stack((y_con,y_m), axis=1)\n",
        "    \n",
        "    return Y,one_hot1,one_hot2\n",
        "#model     \n",
        "ini = 'glorot_uniform'\n",
        "init=tf.global_variables_initializer()\n",
        "X = tf.placeholder(\"float\", [4,3])\n",
        "Y = tf.placeholder(\"float\", [4,5])\n",
        "x3 = tf.placeholder(\"float\", [4,3])\n",
        "x4 = tf.placeholder(\"float\", [4,3])\n",
        "initializer = tf.contrib.layers.xavier_initializer()\n",
        "\n",
        "\n",
        "def encoderA1(x1):\n",
        "     layer_1 = Dense(5, activation=tf.nn.relu, init=ini)(x1)\n",
        "     layer_batch = BatchNormalization(momentum=0.99, epsilon=0.00001, center=True,scale=True)(layer_1)\n",
        "     Q = Dense(3, activation='linear', init=ini)(layer_batch)    \n",
        "     K = Dense(3, activation='linear', init=ini)(layer_batch)\n",
        "     V = Dense(3, activation='linear', init=ini)(layer_batch)\n",
        "     E = tf.matmul(Q,tf.transpose(K))\n",
        "     layer_3 = Dense(4, activation=tf.nn.sigmoid, init=ini)(E)\n",
        "     A1 = tf.matmul(layer_3,V)\n",
        "     return A1\n",
        "def encoderA2(x2):\n",
        "     layer_1 = Dense(5, activation=tf.nn.relu, init=ini)(x2)\n",
        "     layer_batch = BatchNormalization(momentum=0.99, epsilon=0.00001, center=True,scale=True)(layer_1)\n",
        "     Q = Dense(3, activation='linear', init=ini)(layer_batch)    \n",
        "     K = Dense(3, activation='linear', init=ini)(layer_batch)\n",
        "     V = Dense(3, activation='linear', init=ini)(layer_batch)\n",
        "     E = tf.matmul(Q,tf.math.transpose(K))\n",
        "     layer_3 = Dense(4, activation=tf.nn.sigmoid, init=ini)(E)\n",
        "     A2 = tf.matmul(layer_3,V)\n",
        "     return A2\n",
        "def encoder(x3,x4):\n",
        "    A = tf.concat((x3,x4), axis=1)\n",
        "    normA= BatchNormalization(momentum=0.99, epsilon=0.00001, center=True,scale=True)(A)\n",
        "    P = Dense(4, activation=tf.nn.relu, init=ini)(normA)\n",
        "    O = Dense(5, activation='linear', init=ini)(P)\n",
        "    return O\n",
        "X1 = encoderA1(X)\n",
        "X2 = encoderA2(X)\n",
        "y_pred = encoder(X1,X2)\n",
        "y_true = Y\n",
        "\n",
        "cost = tf.reduce_mean(tf.pow(y_true - y_pred, 2))\n",
        "learning_rate = tf.placeholder(tf.float32, shape=[])\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "init = tf.global_variables_initializer()\n",
        "\n"
      ],
      "metadata": {
        "id": "Li2R1cW2LuY7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}